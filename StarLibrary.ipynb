{
 "metadata": {
  "name": "",
  "signature": "sha256:269a7af51f9efb333b80685463c352fc21ad88506d1c83de985c3e587b2fe0c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starlibrary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load starlibrary.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# File: starlibrary.py (modified from starlab.py)\n",
      "# Name: Nicholas Miller\n",
      "# Date: 10.10.14\n",
      "# Desc: Program provides the necessary tools for cluster simulations\n",
      "# \t\t(modified form Dr. Cavendish McKay's starlab.py file\n",
      "# Usage: The program reads input containing details for cluster structure.\n",
      "#        The program prompts cpus to simulate clusters and export output.\n",
      "\n",
      "# <Imports>\n",
      "\n",
      "from subprocess import Popen, PIPE\n",
      "import os\n",
      "import datetime\n",
      "import re\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from lxml import etree\n",
      "import uuid\n",
      "import glob\n",
      "import pickle\n",
      "#import pylab as plt\n",
      "\n",
      "\n",
      "warehousepath = \".warehouse/\"   \n",
      "\n",
      "\n",
      "# <Class creation>\n",
      "\n",
      "class Story:\n",
      "    def __init__(self):\n",
      "        self.story_lines = []\n",
      "        self.story_vals = dict()\n",
      "        self.story_subobjects = []\n",
      "        self.kind = None\n",
      "        return\n",
      "    def __str__(self):\n",
      "        return \"%s, %d lines, %d values, %d subobjects\" % (self.kind, len(self.story_lines), len(self.story_vals.keys()), len(self.story_subobjects))\n",
      "    def process_line(self, line):\n",
      "        # if we can tokenize into an equality, store in the dict, otherwise as a line.\n",
      "        chunks = re.split('=', line)\n",
      "#        print chunks, len(chunks)\n",
      "        if len(chunks) == 2:\n",
      "            self.story_vals[chunks[0].strip()] = chunks[1].strip()\n",
      "        else:\n",
      "            self.story_lines.append(line)\n",
      "\n",
      "# <set up the Run>\n",
      "class Run:\n",
      "    def __init__(self, kingmodel=True, w0=1.5, nstars=2500, masstype=1, runlength=100, exponent=-2.35, binarypercent=.1, binarypoplower = 1.0, binarypopupper = 10):\n",
      "\n",
      "        self.kingmodel = kingmodel\n",
      "        self.w0 = w0\n",
      "        self.nstars = nstars\n",
      "\n",
      "        # mass scaling\n",
      "        self.masstype=masstype\n",
      "        self.exponent=exponent\n",
      "        self.lowerlimit = 0.1\n",
      "        self.upperlimit = 20\n",
      "\n",
      "        # binary scaling\n",
      "        self.binarypercent = binarypercent\n",
      "        self.binarylimit = 0.25\n",
      "        self.binarypoplower = binarypoplower\n",
      "        self.binarypopupper = binarypopupper\n",
      "\n",
      "        # kira parameters\n",
      "        self.runlength=runlength\n",
      "        self.diagout = 0.5\n",
      "        self.dumpout = 0.5\n",
      "        \n",
      "# <codecell>\n",
      "def parse_output(results):\n",
      "    stories = []\n",
      "    lines = re.split(\"\\n\", results)\n",
      "\n",
      "    nextidx = -1\n",
      "    \n",
      "    for index, line in enumerate(lines):\n",
      "        if index >= nextidx:\n",
      "            storystart = re.match(\"^\\((\\w+)\",line)\n",
      "            if storystart:\n",
      "                #print \"in parse_output, calling parse_lines:\", index, storystart.group(1)\n",
      "                nextidx, newstory = parse_lines(lines, index+1, storystart.group(1))\n",
      "                #print \"in parse_output, back from parse_lines:\", nextidx, str(newstory)\n",
      "                stories.append(newstory)\n",
      "    return stories\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def parse_lines(lines, startidx, name):\n",
      "    thestory = Story()\n",
      "    thestory.kind = name\n",
      "    nextidx = -1\n",
      "    for index,line in enumerate(lines[startidx:]):\n",
      "        if index >= nextidx-startidx:\n",
      "            #print \"%s Line is %s\"%(name, line)\n",
      "            storystart = re.match(\"^\\((\\w+)\",line)\n",
      "            storyend = re.match(\"\\)%s\"%name, line)\n",
      "            if storyend: # we've hit the end of our story; get out and pass it back up\n",
      "                endindex = index\n",
      "                break\n",
      "            elif storystart: # new story; start up a new parse_lines\n",
      "                #print \"in parse_lines, calling parse_lines:\", startidx+index+1, storystart.group(1)\n",
      "                nextidx, newstory = parse_lines(lines, startidx+index + 1, storystart.group(1))\n",
      "                #print \"back\", nextidx, str(newstory)\n",
      "                thestory.story_subobjects.append(newstory)\n",
      "            else:\n",
      "                thestory.process_line(line)\n",
      "    return endindex+startidx+1, thestory\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def extract_particle_dynamics(story):\n",
      "    \"\"\" recursively extract dynamics objects to get masses, positions, and velocities.\n",
      "\n",
      "    Be careful of particles with subparticles.\"\"\"\n",
      "    particles = []\n",
      "    if story.kind == \"Particle\":\n",
      "        if len(story.story_subobjects) > 4:\n",
      "            # get r, v, as center of mass quantities\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Dynamics':\n",
      "                    xcom, ycom, zcom = subobj.story_vals['r'].split(\" \")\n",
      "                    vxcom, vycom, vzcom = subobj.story_vals['v'].split(\" \")\n",
      "            # get relative positions and velocities of sub-particles\n",
      "            subparticles = []\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Particle':\n",
      "                    subparticles.extend(extract_particle_dynamics(subobj))\n",
      "                    \n",
      "            # add COM r, v to sub-particles, and append\n",
      "            for particle in subparticles:\n",
      "                particles.append((particle[0] + float(xcom),\n",
      "                                  particle[1] + float(ycom),\n",
      "                                  particle[2] + float(zcom),\n",
      "                                  particle[3] + float(vxcom),\n",
      "                                  particle[4] + float(vycom),\n",
      "                                  particle[5] + float(vzcom),\n",
      "                                  particle[6]))\n",
      "        else: # only 4 subobjects, so this is an individual star\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Dynamics':\n",
      "                    x,y,z = subobj.story_vals['r'].split(\" \")\n",
      "                    vx,vy,vz = subobj.story_vals['v'].split(\" \")\n",
      "                    m = subobj.story_vals['m']\n",
      "                    particles.append((float(x), float(y), float(z), float(vx), float(vy), float(vz), float(m)) )\n",
      "    return particles\n",
      "    \n",
      "# <codecell>\n",
      "\n",
      "def vis_story_3d(story_list):\n",
      "    \"\"\"visualize a story list. \"\"\"\n",
      "    \n",
      "    xvals = []\n",
      "    yvals = []\n",
      "    zvals = []\n",
      "    vxs = []\n",
      "    vys = []\n",
      "    vzs = []\n",
      "    masses = []\n",
      "    \n",
      "    for story in story_list:\n",
      "        partlist = extract_particle_dynamics(story)\n",
      "        \n",
      "    for particle in partlist:\n",
      "        xvals.append(particle[0])\n",
      "        yvals.append(particle[1])\n",
      "        zvals.append(particle[2])\n",
      "        vxs.append(particle[3])\n",
      "        vys.append(particle[4])\n",
      "        vzs.append(particle[5])\n",
      "        masses.append(particle[6])\n",
      "        \n",
      "    # now do the plot\n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.plot(np.array(xvals), np.array(yvals), np.array(zvals), \".\")\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def premain(startn):\n",
      "    \"\"\"Run a plummer model for 10 dynamical times and return the number of stars remaining.\"\"\"\n",
      "    from subprocess import Popen, PIPE\n",
      "    from starlibrary import parse_output, extract_particle_dynamics\n",
      "    import random\n",
      "    \n",
      "    seed = random.randint(0,9999999999)\n",
      "    \n",
      "    print \"running %d particles\" % startn\n",
      "    cmds = []\n",
      "\n",
      "    cmds.append([\"makeking\", \"-n\", \"%d\"%startn, \"-w\", \"5\", \"-i\",  \"-u\", \"-s\", \"%d\"%seed])\n",
      "    cmds.append([\"makemass\", \"-f\", \"2\", \"-l\", \"0.1,\", \"-u\", \"20\"])\n",
      "    cmds.append([\"makesecondary\", \"-f\", \"0.1\", \"-l\", \"0.25\"])\n",
      "    cmds.append([\"makebinary\", \"-l\", \"1\", \"-u\", \"10\"])\n",
      "    cmds.append([\"scale\", \"-m\", \"1\", \"-e\", \"-0.25\", \"-q\", \"0.5\"]) \n",
      "    cmds.append([\"kira\", \"-t\", \"100\", \"-d\", \"1\", \"-D\", \"2\", \"-f\", \"0.3\", \"-n\", \"10\", \"-q\", \"0.5\", \"-G\", \"2\", \"-B\"])\n",
      "\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        print index, cmd\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
      "    inp = procs[-1].stdout\n",
      "    \n",
      "    result = procs[-1].communicate()\n",
      "    slist = parse_output(result[0])\n",
      "    return len(extract_particle_dynamics(slist[-1]))\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def grab_energies(slist):\n",
      "    times = []\n",
      "    energies = []\n",
      "    kinetics = []\n",
      "    potentials = []\n",
      "    for story in slist:\n",
      "        times.append(float(slist.story_subobjects[1].story_vals['t']))\n",
      "        energies.append(float(slist.story_subobjects[1].story_vals['total_energy']))\n",
      "        kinetics.append(float(slist.story_subobjects[1].story_vals['kinetic_energy']))\n",
      "        potentials.append(float(slist.story_subobjects[1].story_vals['potential_energy']))\n",
      "    return times, energies, kinetics, potentials\n",
      "# <codecell>\n",
      "\n",
      "def l2norm(E, U, T):\n",
      "    U0 = 2*E[0]\n",
      "    T0 = -E[0]\n",
      "    l2U = sum((np.array(U)-U0)**2)\n",
      "    l2T = sum((np.array(T)-T0)**2)\n",
      "    return l2U, l2T\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def fs_process_commands(cmds):\n",
      "    \"\"\"Process commands, storing the results on the filesystem.\"\"\"\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE))\n",
      "        inp = procs[-1].stdout\n",
      "    result = procs[-1].communicate()\n",
      "\n",
      "    theuuid = uuid.uuid1()\n",
      "    storename = str(theuuid)+\".kiraout\"\n",
      "\n",
      "    #if not os.path.isdir(warehousepath):\n",
      "    #    os.makedirs(warehousepath)\n",
      "\n",
      "    store = open(warehousepath+storename, \"w\")\n",
      "        \n",
      "    store.write(result[0])\n",
      "    store.close()\n",
      "    \n",
      "    return theuuid\n",
      "\n",
      "# <codecell>\n",
      "def fs_panel(storename):\n",
      "    \"\"\"Grab a story list from the filesystem and turn it into a pandas panel.\"\"\"\n",
      "    infile = open(storename, 'rb')\n",
      "    partstart = re.compile(\"^\\(Particle\")\n",
      "    partend = re.compile(\"^\\)Particle\")\n",
      "    dynstart = re.compile(\"^\\(Dynamics\")\n",
      "    dynend = re.compile(\"^\\)Dynamics\")\n",
      "\n",
      "    snap = 0\n",
      "    insnap = False\n",
      "    panbase = pd.Panel()\n",
      "    \n",
      "    for line in infile:\n",
      "        if partstart.match(line):\n",
      "            pass\n",
      "        elif partend.match(line):\n",
      "            pass\n",
      "        elif dynstart.match(line):\n",
      "            pass\n",
      "        elif dynend.match(line):\n",
      "            pass\n",
      "        \n",
      "    return pan\n",
      "\n",
      "\n",
      "# <codecell>\n",
      "def kiraout_to_xml(theuuid):\n",
      "    storebase = str(theuuid)\n",
      "    storename = str(theuuid)+\".kiraout\"\n",
      "    \n",
      "    xmlframes = []\n",
      "\n",
      "    frame = 0\n",
      "    nframes = 0\n",
      "    level = 0\n",
      "    \n",
      "    store = open(warehousepath+storename, \"rb\")\n",
      "\n",
      "    storystart = re.compile(\"^\\((\\w+)\")\n",
      "    storyend = re.compile(\"^\\)(\\w+)\")\n",
      "\n",
      "    for line in store:\n",
      "        if storystart.match(line):\n",
      "            #print \"entering: %s, %d\" % (storystart.match(line).group(1), level)\n",
      "            if level==0:\n",
      "                nframes += 1\n",
      "                xmlname = storebase + \".%d.xml\" % frame\n",
      "                xmlframes.append(xmlname)\n",
      "                xmlfile = open(warehousepath+xmlname, \"wb\")\n",
      "                xmlfile.write('<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>')\n",
      "            level += 1\n",
      "            xmlfile.write(\"<%s>\\n\"%storystart.match(line).group(1))\n",
      "        elif storyend.match(line):\n",
      "            #print \"leaving: %s, %d\" % (storyend.match(line).group(1), level)\n",
      "            level -= 1\n",
      "            xmlfile.write(\"</%s>\\n\"%storyend.match(line).group(1))\n",
      "            if level == 0:\n",
      "                frame += 1\n",
      "                xmlfile.close()\n",
      "        else:\n",
      "            chunks = re.split(\"=\", line)\n",
      "            if len(chunks) == 2:\n",
      "                xmlfile.write(\"<value %s=\\\"%s\\\" />\\n\" %(re.sub(\"\\,* \",\"_\",chunks[0].strip()), chunks[1].strip()))\n",
      "            else:\n",
      "                xmlfile.write(line)\n",
      "\n",
      "    store.close()\n",
      "    return nframes\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "\n",
      "def quantile_radius(pan, quant):\n",
      "    \"\"\"Get the average radius for a given mass quantile.\n",
      "\n",
      "    Compares the average radius for the given mass quantile 0% -> quant\n",
      "    with that of the complement ((1-quant) -> 100%)\n",
      "\n",
      "    Takes inputs:\n",
      "    pan -- pandas panel, where the item index is sorted by mass\n",
      "    quant -- the quantile, in percent, to use.\n",
      "\n",
      "    returns a tuple of time series:\n",
      "    (lightradius, heavyradius, light/heavy) \n",
      "    \"\"\"\n",
      "    indices = sorted(pan.keys(), key=int)\n",
      "    number = int(quant*len(indices))\n",
      "    print \"%d runs in requested quantile\" % number\n",
      "    heavyslice = [pan[index] for index in indices[:number]]\n",
      "    lightslice = [pan[index] for index in indices[-number:]]\n",
      "    \n",
      "    print \"heavy masses:\", [star['m'][0] for star in heavyslice]\n",
      "    print \"light masses:\", [star['m'][0] for star in lightslice]\n",
      "    \n",
      "    heavyr = np.zeros_like(heavyslice[0]['radius'].values)\n",
      "    for star in heavyslice:\n",
      "        heavyr += star['radius'].values\n",
      "    heavyr /= number\n",
      "    \n",
      "    lightr = np.zeros_like(lightslice[0]['radius'].values)\n",
      "    for star in lightslice:\n",
      "        lightr += star['radius'].values\n",
      "    lightr /= number\n",
      "    \n",
      "    ratio = lightr/heavyr\n",
      "    return lightr, heavyr, ratio\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "from matplotlib import animation\n",
      "def animate_panel_old(pan, prng=10.0, filebase='basic_animation'):\n",
      "    \"\"\"Turn a panel of star cluster evolution snapshots into a 3d animation.\n",
      "\n",
      "    Arguments are:\n",
      "    pan: the panel\n",
      "    prng: plot range for all three axes.\n",
      "    filebase: the base name of the file for the animation.\n",
      "\n",
      "    returns:\n",
      "    Nothing.\"\"\"\n",
      "    \n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.set_autoscale_on(False)\n",
      "    \n",
      "    nframes = pan.shape[1]\n",
      "    starfield, = ax.plot([], [], [],'bo', ms=7)\n",
      "    ax.set_xlim3d(-prng, prng)\n",
      "    ax.set_ylim3d(-prng, prng)\n",
      "    ax.set_zlim3d(-prng, prng)\n",
      "\n",
      "    def init():\n",
      "        \"\"\"initialize animation\"\"\"\n",
      "        starfield.set_data([], [])\n",
      "        starfield.set_3d_properties(zs=[])\n",
      "        return starfield\n",
      "    \n",
      "    def doframe(n):\n",
      "        xvals = []\n",
      "        yvals = []\n",
      "        zvals = []\n",
      "        masses = []\n",
      "        \n",
      "        for starid in pan.keys():\n",
      "            xvals.append(pan[starid]['r'][n][0])\n",
      "            yvals.append(pan[starid]['r'][n][1])\n",
      "            zvals.append(pan[starid]['r'][n][2])\n",
      "            masses.append(pan[starid]['m'][n])\n",
      "    # not super happy with the colors yet.\n",
      "        starfield.set_data(np.array(xvals), np.array(yvals))\n",
      "        starfield.set_3d_properties(zs=np.array(zvals))\n",
      "        return starfield\n",
      "\n",
      "    anim = animation.FuncAnimation(fig, doframe,\n",
      "                               frames=nframes, interval=20, blit=True)\n",
      "    anim.save(\"%s.mp4\"%filebase, fps=30)\n",
      "    #ax.plot(np.array(xvals), np.array(yvals), np.array(zvals), \".\")\n",
      "\n",
      "\n",
      "def animate_from_fs(filebase, nframes, prng=10.0, use_warehouse=True):\n",
      "    import pylab as plt\n",
      "    from mpl_toolkits.mplot3d import axes3d\n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.set_autoscale_on(False)\n",
      "\n",
      "    mcomfield, = ax.plot([], [], [],'go', ms=7)\n",
      "    ax.set_xlim3d(-prng, prng)\n",
      "    ax.set_ylim3d(-prng, prng)\n",
      "    ax.set_zlim3d(-prng, prng)\n",
      "\n",
      "    def init():\n",
      "        \"\"\"initialize animation\"\"\"\n",
      "        mcomfield.set_data([], [])\n",
      "        mcomfield.set_3d_properties(zs=[])\n",
      "        return (mcomfield)\n",
      "    \n",
      "    def doframe(n):\n",
      "        xvals = []\n",
      "        yvals = []\n",
      "        zvals = []\n",
      "        masses = []\n",
      "        \n",
      "        if use_warehouse:\n",
      "            xmlname = warehousepath + filebase + \".%d.xml\"% n\n",
      "        else:\n",
      "            xmlname = filebase + \".%d.xml\"% n\n",
      "            \n",
      "        dataframe, time, nparticles = process_frame(xmlname)\n",
      "        \n",
      "        xvals = dataframe.xs('x').values\n",
      "        yvals = dataframe.xs('y').values\n",
      "        zvals = dataframe.xs('z').values\n",
      "        \n",
      "        mcomfield.set_data(dataframe.xs('x_mcom').values, dataframe.xs('y_mcom').values)\n",
      "        mcomfield.set_3d_properties(zs=np.array(dataframe.xs('z_mcom').values))\n",
      "        return (mcomfield)\n",
      "\n",
      "    anim = animation.FuncAnimation(fig, doframe,\n",
      "                               frames=nframes, interval=20, blit=True)\n",
      "    moviename = \"%s.mp4\"%filebase\n",
      "    anim.save(moviename, fps=30, bitrate=4000)\n",
      "    return moviename\n",
      "\n",
      "def str_to_vect(vectstr):\n",
      "    return np.array(vectstr.split(\" \"), float)\n",
      "\n",
      "def process_frame(xmlname):\n",
      "    frame = etree.parse(xmlname)\n",
      "    nparticles = int(frame.xpath('/Particle/value[@ N]/@ N')[0])\n",
      "    time = float(frame.xpath('/Particle/Dynamics/value[@ t]/@ t')[0])\n",
      "    \n",
      "    center_r = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ r]/@ r')[0])\n",
      "    com_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ com_pos]/@ com_pos')[0])\n",
      "    mcom_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ mcom_pos]/@ mcom_pos')[0])\n",
      "    mass_scale = float(frame.xpath('/Particle/Star/value[@ mass_scale]/@ mass_scale')[0])\n",
      "    time_scale = float(frame.xpath('/Particle/Star/value[@ time_scale]/@ time_scale')[0])\n",
      "    size_scale = float(frame.xpath('/Particle/Star/value[@ size_scale]/@ size_scale')[0])\n",
      "\n",
      "    particledict = {}\n",
      "    for part in frame.xpath('/Particle/Particle'):\n",
      "        subpartdict = flatten_particle(part)\n",
      "        particledict.update(subpartdict)\n",
      "    for key in particledict.keys():\n",
      "        particledict[key]['x_mcom'] = particledict[key]['x'] - mcom_pos[0] + center_r[0]\n",
      "        particledict[key]['y_mcom'] = particledict[key]['y'] - mcom_pos[1] + center_r[1]\n",
      "        particledict[key]['z_mcom'] = particledict[key]['z'] - mcom_pos[2] + center_r[2]\n",
      "        particledict[key]['x_com'] = particledict[key]['x'] - com_pos[0] + center_r[0]\n",
      "        particledict[key]['y_com'] = particledict[key]['y'] - com_pos[1] + center_r[1]\n",
      "        particledict[key]['z_com'] = particledict[key]['z'] - com_pos[2] + center_r[2]\n",
      "    framedataframe = pd.DataFrame(particledict)\n",
      "    \n",
      "    return framedataframe, time, nparticles\n",
      "\n",
      "def xml_to_panel(basename, nframes):\n",
      "    paneldict = {}\n",
      "    for frame in xrange(nframes):\n",
      "        xmlname = basename + \".%d.xml\"%frame\n",
      "        df, time, nparticles = process_frame(xmlname)\n",
      "        paneldict[time] = df\n",
      "    thepanel = pd.Panel(paneldict)\n",
      "    return thepanel.transpose(items='minor', major='items', minor='major')\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def process_commands(cmds):\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
      "        inp = procs[-1].stdout\n",
      "    \n",
      "    result = procs[-1].communicate()\n",
      "    return result\n",
      "\n",
      "def story_list_to_panel(slist):\n",
      "    nsnaps = len(slist)\n",
      "    nstars = slist[0].story_vals['N']\n",
      "    dict_for_panel = {}\n",
      "    \n",
      "    for snapnum, snapstory in enumerate(slist):\n",
      "        partlist = flatten_parts(snapstory.story_subobjects[4:], snapstory.story_subobjects[1])\n",
      "        for part in partlist:\n",
      "            # make the star dict if necessary\n",
      "            starlabel = part[\"i\"]\n",
      "            pos = part['r']\n",
      "            radius = np.sqrt(pos.dot(pos))\n",
      "            if dict_for_panel.get(starlabel,None) == None:\n",
      "                dict_for_panel[starlabel] = {}\n",
      "                for key in part.keys():\n",
      "                    dict_for_panel[starlabel][key] = [ part[key] ]\n",
      "                dict_for_panel[starlabel]['radius'] = [ radius ]\n",
      "            else:\n",
      "                for key in part.keys():\n",
      "                    try:\n",
      "                        dict_for_panel[starlabel][key].append(part[key])\n",
      "                    except KeyError:\n",
      "                        dict_for_panel[starlabel][key] = [ None ] * snapnum\n",
      "                        dict_for_panel[starlabel][key].append(part[key])\n",
      "                dict_for_panel[starlabel]['radius'].append(radius)\n",
      "            # check to see if anything is missing...\n",
      "            reflength = len(dict_for_panel[starlabel]['radius'])\n",
      "            for key in dict_for_panel[starlabel].keys():\n",
      "                if len(dict_for_panel[starlabel][key]) < reflength:\n",
      "                       #print \"Whoa. problem. i=%s, t=%s, key=%s\" % (starlabel, snapnum, key)\n",
      "                       dict_for_panel[starlabel][key].append(None)\n",
      "\n",
      "#    print \"number of stars: \",len(dict_for_panel.keys())\n",
      "#    for key in dict_for_panel.keys():\n",
      "#        lengthlist = [len(dict_for_panel[key][subkey]) for subkey in dict_for_panel[key].keys()]\n",
      "#        print key, lengthlist\n",
      "#        print dict_for_panel[key].keys()\n",
      "#        print \"-------------------------\\n\\n\"\n",
      "        \n",
      "    thepanel = pd.Panel(dict_for_panel)\n",
      "    return thepanel\n",
      "\n",
      "def flatten_parts(partlist, parentinfo):\n",
      "    flattened = []\n",
      "    for partnum, part in enumerate(partlist):\n",
      "        if len(part.story_subobjects) > 4:\n",
      "            flattened.extend(flatten_parts(part.story_subobjects[4:], part.story_subobjects[1]))\n",
      "        else:\n",
      "            partdict = dict(part.story_vals, **part.story_subobjects[1].story_vals)\n",
      "            flattened.append(partdict)\n",
      "    # deal with positions\n",
      "    pos = np.array(parentinfo.story_vals['r'].split(\" \"), float)\n",
      "    for part in flattened:\n",
      "        try:\n",
      "            part['r'] = part['r'] + pos\n",
      "        except TypeError:\n",
      "            part['r'] = np.array(part['r'].split(\" \"), float) + pos\n",
      "    return flattened\n",
      "\n",
      "\n",
      "def single_run(therun):\n",
      "    \"\"\"Perform a single run from a Run object.\"\"\"\n",
      "    cmds = []\n",
      "\n",
      "    if therun.kingmodel:\n",
      "        cmds.append([\"makeking\",\n",
      "                      \"-n\", \"%d\"%therun.nstars,\n",
      "                      \"-w\", \"%3.1f\"%therun.w0,\n",
      "                      \"-i\"])\n",
      "    else:\n",
      "        cmds.append([\"makeplummer\",\n",
      "                      \"-n\", \"%d\"%therun.nstars,\n",
      "                      \"-i\"])\n",
      "\n",
      "    cmds.append([\"makemass\",\n",
      "                  \"-f\", \"%d\"%therun.masstype,\n",
      "                  \"-l\", \"%f\"%therun.lowerlimit,\n",
      "                  \"-u\", \"%f\"%therun.upperlimit,\n",
      "                  \"-i\"])\n",
      "\n",
      "    cmds.append([\"makesecondary\",\n",
      "                  \"-f\", \"%d\"%therun.binarypercent,\n",
      "                  \"-l\", \"%f\"%therun.binarylimit\n",
      "\t\t])\n",
      "\n",
      "    cmds.append([\"scale\",\n",
      "                  \"-m\", \"1\",\n",
      "                  \"-e\", \"-0.25\",\n",
      "                  \"-q\", \"0.5\"])\n",
      "\n",
      "    cmds.append([\"makebinary\",\n",
      "                  \"-l\", \"%d\"%therun.binarypoplower,\n",
      "                  \"-u\", \"%f\"%therun.binarypopupper\n",
      "\t\t])\n",
      "\n",
      "    cmds.append([\"kira\", \"-t\", \"%d\"%therun.runlength,\n",
      "                  \"-d\", \"%f\"%therun.diagout,\n",
      "                  \"-D\", \"%f\"%therun.dumpout,\n",
      "                  \"-n\", \"10\",\n",
      "                  \"-q\", \"0.5\"])\n",
      "\n",
      "    therun.uuid = fs_process_commands(cmds)\n",
      "    therun.nframes = kiraout_to_xml(therun.uuid)\n",
      "    return therun\n",
      "\n",
      "def animate_run(therun):\n",
      "    theuuid = therun.uuid\n",
      "    moviename = animate_from_fs(str(theuuid), therun.nframes, use_warehouse=True)\n",
      "    return moviename\n",
      "\n",
      "def flatten_particle(part):\n",
      "    \"\"\"Turn a prarticle into a dictionary with the appropriate values, recursing if necessary.\"\"\"\n",
      "    nparticles = int(part.xpath('./value[@ N]/@ N')[0])\n",
      "    #print nparticles\n",
      "    r = str_to_vect(part.xpath('./Dynamics/value[@ r]/@ r')[0])\n",
      "    v = str_to_vect(part.xpath('./Dynamics/value[@ v]/@ v')[0])\n",
      "    \n",
      "    if nparticles == 1:\n",
      "        parti = int(part.xpath('./value[@ i]/@ i')[0])\n",
      "        m = float(part.xpath('./Dynamics/value[@ m]/@ m')[0])\n",
      "        radius = np.sqrt(r.dot(r))\n",
      "        pot = float(part.xpath('./Dynamics/value[@ pot]/@ pot')[0])\n",
      "        partdict = {parti: {'x':r[0], 'y':r[1], 'z':r[2], 'm':m, 'radius':radius} }\n",
      "        partdict[parti].update({'vx':v[0], 'vy':v[1], 'vz':v[2], 'pot':pot})\n",
      "    else:\n",
      "        # this node is not a leaf; we have to do the subtree\n",
      "        partdict = {}\n",
      "        for subpart in part.xpath('./Particle'):\n",
      "            tpd = flatten_particle(subpart)\n",
      "            #print tpd\n",
      "            partdict.update(tpd)\n",
      "        for key in partdict.keys():\n",
      "            partdict[key]['x'] += r[0]\n",
      "            partdict[key]['y'] += r[1]\n",
      "            partdict[key]['z'] += r[2]\n",
      "            partdict[key]['vx'] += v[0]\n",
      "            partdict[key]['vy'] += v[1]\n",
      "            partdict[key]['vz'] += v[2]\n",
      "            partdict[key]['radius'] = np.sqrt(partdict[key]['x']**2+partdict[key]['y']**2+partdict[key]['z']**2)\n",
      "            partdict[key]['kinetic'] = (partdict[key]['vx']**2+partdict[key]['vy']**2+partdict[key]['vz']**2)*partdict[key]['m']/2.0\n",
      "    return partdict\n",
      "\n",
      "def extract_from_frame(therun, framenum):\n",
      "    filebase = str(therun.uuid)\n",
      "    xmlname = '.warehouse/' + filebase + \".%d.xml\" % framenum\n",
      "    frame = etree.parse(xmlname)\n",
      "\n",
      "    extracted = {}\n",
      "    \n",
      "    nparticles = int(frame.xpath('/Particle/value[@ N]/@ N')[0])\n",
      "    time = float(frame.xpath('/Particle/Dynamics/value[@ t]/@ t')[0])\n",
      "\n",
      "    center_r = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ r]/@ r')[0])\n",
      "    com_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ com_pos]/@ com_pos')[0])\n",
      "    mcom_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ mcom_pos]/@ mcom_pos')[0])\n",
      "    mass_scale = float(frame.xpath('/Particle/Star/value[@ mass_scale]/@ mass_scale')[0])\n",
      "    time_scale = float(frame.xpath('/Particle/Star/value[@ time_scale]/@ time_scale')[0])\n",
      "    size_scale = float(frame.xpath('/Particle/Star/value[@ size_scale]/@ size_scale')[0])\n",
      "\n",
      "    particledict = {}\n",
      "    for part in frame.xpath('/Particle/Particle'):\n",
      "        subpartdict = flatten_particle(part)\n",
      "        particledict.update(subpartdict)\n",
      "    for key in particledict.keys():\n",
      "        particledict[key]['x_mcom'] = particledict[key]['x'] - mcom_pos[0] + center_r[0]\n",
      "        particledict[key]['y_mcom'] = particledict[key]['y'] - mcom_pos[1] + center_r[1]\n",
      "        particledict[key]['z_mcom'] = particledict[key]['z'] - mcom_pos[2] + center_r[2]\n",
      "        particledict[key]['x_com'] = particledict[key]['x'] - com_pos[0] + center_r[0]\n",
      "        particledict[key]['y_com'] = particledict[key]['y'] - com_pos[1] + center_r[1]\n",
      "        particledict[key]['z_com'] = particledict[key]['z'] - com_pos[2] + center_r[2]\n",
      "        particledict[key]['radius'] = np.sqrt(particledict[key]['x_mcom']**2 +\n",
      "                                              particledict[key]['y_mcom']**2 +\n",
      "                                              particledict[key]['z_mcom']**2)\n",
      "    framedataframe = pd.DataFrame(particledict)\n",
      "\n",
      "    return framedataframe, time, nparticles\n",
      "\n",
      "def run_to_panel(therun):\n",
      "    nframes = int(therun.runlength/therun.dumpout)\n",
      "    paneldict={}\n",
      "    for frame in xrange(nframes):\n",
      "        df, time, nparticles = extract_from_frame(therun, frame)\n",
      "        paneldict[time] = df\n",
      "    thepanel = pd.Panel(paneldict)\n",
      "    return thepanel.transpose(items='major', major='minor', minor='items')\n",
      "\n",
      "def massradius(pan, quantity='radius', fraction=0.1):\n",
      "    times = pan[quantity].keys()\n",
      "    high_mass_radius_list = []\n",
      "    low_mass_radius_list = []\n",
      "    nstars = pan[quantity][times[0]].count()\n",
      "    nfrac = int(nstars * fraction)\n",
      "    \n",
      "    hmseries = pan[quantity][0:nfrac].median()\n",
      "    lmseries = pan[quantity][-nfrac:-1].median()\n",
      "    ratioseries = lmseries/hmseries\n",
      "        #print time, hmr, lmr\n",
      "        \n",
      "#    lmseries = pd.Series(data=low_mass_radius_list, index=times)\n",
      "#    hmseries = pd.Series(data=high_mass_radius_list, index=times)\n",
      "#    ratioseries = pd.Series(data=ratios, index=times)\n",
      "    return(ratioseries, lmseries, hmseries)\n",
      "\n",
      "def list_ensembles():\n",
      "    ensfiles= glob.glob('./*.ensemble')\n",
      "    print \"%d ensembles:\\n\" % len(ensfiles)\n",
      "    for ensf in ensfiles:\n",
      "        ensfile = open(ensf, 'rb')\n",
      "        try:\n",
      "            runslist = pickle.load(ensfile)\n",
      "            nruns = len(runslist)\n",
      "            nstars = runslist[0].nstars\n",
      "            if runslist[0].kingmodel:\n",
      "                model = \"King\"\n",
      "            else:\n",
      "                model = \"Plummer\"\n",
      "            print \"%s -- %s model; %d runs %d stars \" %(ensf, model, nruns, nstars)\n",
      "        except EOFError:\n",
      "            print \"%s -- No data\" %ensf\n",
      "        ensfile.close()\n",
      "\n",
      "\n",
      "def avg_series(ensname, output=False):\n",
      "    storename = \"%s-avg.h5\"%ensname\n",
      "    store = pd.HDFStore(\"%s-avg.h5\"%ensname)\n",
      "    try:\n",
      "        ratiodf = store['ratiodf']\n",
      "        lowdf = store['lowdf']\n",
      "        highdf = store['highdf']\n",
      "    except KeyError:\n",
      "        ensfile = open(ensname, 'rb')\n",
      "        runlist = pickle.load(ensfile)\n",
      "\n",
      "        rsdict = {}\n",
      "        lsdict = {}\n",
      "        hsdict = {}\n",
      "        i = 0\n",
      "        for run in runlist:\n",
      "            key = \"%d\"%i\n",
      "            if output:\n",
      "                print key\n",
      "            try:\n",
      "                thepan = run_to_panel(run)\n",
      "                rseries, lmseries, hmseries = massradius(thepan)\n",
      "                rsdict[key] = rseries\n",
      "                lsdict[key] = lmseries\n",
      "                hsdict[key] = hmseries\n",
      "            except IOError:\n",
      "                pass\n",
      "            i+=1\n",
      "        highdf = pd.DataFrame(hsdict)\n",
      "        lowdf = pd.DataFrame(lsdict)\n",
      "        ratiodf = pd.DataFrame(rsdict)\n",
      "    \n",
      "        # compute averages\n",
      "        highdf['avg'] = highdf.mean(axis=1)\n",
      "        lowdf['avg'] = lowdf.mean(axis=1)\n",
      "        ratiodf['avg'] = ratiodf.mean(axis=1)\n",
      "    \n",
      "        # compute stddev\n",
      "        highdf['stddev'] = highdf.std(axis=1)\n",
      "        lowdf['stddev'] = lowdf.std(axis=1)\n",
      "        ratiodf['stddev'] = ratiodf.std(axis=1)\n",
      " \n",
      "        store['highdf'] = highdf\n",
      "        store['lowdf'] = lowdf\n",
      "        store['ratiodf'] = ratiodf\n",
      "        \n",
      "    return ratiodf, lowdf, highdf\n",
      "\n",
      "def r_and_m(clusterstep):\n",
      "    rvals = []\n",
      "    masses = []\n",
      "    \n",
      "# determine the radii and masses of stars for a timestep in kira output\n",
      "# uses extract_particle_dynamics to open story and create lists of stars\n",
      "    \n",
      "    partlist = extract_particle_dynamics(clusterstep)\n",
      "    \n",
      "    for particle in partlist:\n",
      "        masses.append(particle[6])\n",
      "        x = particle[0]\n",
      "        y = particle[1]\n",
      "        z = particle[2]\n",
      "        r = np.sqrt(x*x + y*y + z*z)\n",
      "        rvals.append(r)\n",
      "#        print r, particle[6]\n",
      "        \n",
      "    return rvals, masses\n",
      "\n",
      "def medianpos(mlow, mhigh, rad, masses):\n",
      "    index = 0\n",
      "    r_lowmass = []\n",
      "    r_highmass = []\n",
      "    \n",
      "# find median radius for stars below a low mass cut-off and above\n",
      "# a high-mass cut-off given the desired cut-offs as well as lists of\n",
      "# radii and masses (ordered the same)\n",
      "    \n",
      "    for mass in masses:\n",
      "        if mass <= mlow:\n",
      "            r_lowmass.append(rad[index])\n",
      "        if mass >= mhigh:\n",
      "            r_highmass.append(rad[index])\n",
      "        index = index + 1\n",
      "        \n",
      "    medlow = np.median(r_lowmass)\n",
      "    medhigh = np.median(r_highmass)\n",
      "    \n",
      "    return medlow, medhigh\n",
      "\n",
      "def medianpos_percentile(storylist):\n",
      "    masscut = 0.1\n",
      "    first = 1\n",
      "    median_low = []\n",
      "    median_high = []\n",
      "    \n",
      "# takes a storylist generated from kira output and produces a list of\n",
      "# median star positions for stars in the upper & lower percentile as\n",
      "# set in the parameter \"masscut\", above\n",
      "\n",
      "# when looking at the initial timestep, it uses the percentile to figure\n",
      "# out actual cut-offs in mass.  This way, we do not have to worry about \n",
      "# evaporation changing which stars fall in our observed bins.  \n",
      "    \n",
      "    for story in storylist:\n",
      "        (radii, masses) = r_and_m(story)\n",
      "        if first == 1:\n",
      "            masssort = np.sort(masses)\n",
      "            nummass = len(masses)\n",
      "            indexlo = int(np.floor(masscut * nummass))\n",
      "            indexhi = int(np.floor(nummass - indexlo))\n",
      "            masslow = masssort[indexlo]\n",
      "            masshigh = masssort[indexhi]\n",
      "            print masslow, masshigh\n",
      "            first = 0\n",
      "        (medlow, medhigh) = medianpos(masslow, masshigh, radii, masses)\n",
      "        median_low.append(medlow)\n",
      "        median_high.append(medhigh)\n",
      "    return median_low, median_high\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <nbformat>3.0</nbformat>\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "from subprocess import Popen, PIPE\n",
      "import os\n",
      "import datetime\n",
      "import re\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from lxml import etree\n",
      "import uuid\n",
      "import glob\n",
      "import pickle\n",
      "#import pylab as plt\n",
      "\n",
      "\n",
      "warehousepath = \".warehouse/\"   \n",
      "\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "class Story:\n",
      "    def __init__(self):\n",
      "        self.story_lines = []\n",
      "        self.story_vals = dict()\n",
      "        self.story_subobjects = []\n",
      "        self.kind = None\n",
      "        return\n",
      "    def __str__(self):\n",
      "        return \"%s, %d lines, %d values, %d subobjects\" % (self.kind, len(self.story_lines), len(self.story_vals.keys()), len(self.story_subobjects))\n",
      "    def process_line(self, line):\n",
      "        # if we can tokenize into an equality, store in the dict, otherwise as a line.\n",
      "        chunks = re.split('=', line)\n",
      "#        print chunks, len(chunks)\n",
      "        if len(chunks) == 2:\n",
      "            self.story_vals[chunks[0].strip()] = chunks[1].strip()\n",
      "        else:\n",
      "            self.story_lines.append(line)\n",
      "\n",
      "# <codecell>\n",
      "class Run:\n",
      "    def __init__(self, kingmodel=True, w0=1.5, nstars=2500, masstype=1, runlength=100, exponent=-2.35):\n",
      "        self.kingmodel = kingmodel\n",
      "        self.w0 = w0\n",
      "        self.nstars = nstars\n",
      "\n",
      "        # mass scaling\n",
      "        self.masstype=masstype\n",
      "        self.exponent=exponent\n",
      "        self.lowerlimit = 0.1\n",
      "        self.upperlimit = 20\n",
      "\n",
      "        # kira parameters\n",
      "        self.runlength=runlength\n",
      "        self.diagout = 0.5\n",
      "        self.dumpout = 0.5\n",
      "        \n",
      "# <codecell>\n",
      "def parse_output(results):\n",
      "    stories = []\n",
      "    lines = re.split(\"\\n\", results)\n",
      "\n",
      "    nextidx = -1\n",
      "    \n",
      "    for index, line in enumerate(lines):\n",
      "        if index >= nextidx:\n",
      "            storystart = re.match(\"^\\((\\w+)\",line)\n",
      "            if storystart:\n",
      "                #print \"in parse_output, calling parse_lines:\", index, storystart.group(1)\n",
      "                nextidx, newstory = parse_lines(lines, index+1, storystart.group(1))\n",
      "                #print \"in parse_output, back from parse_lines:\", nextidx, str(newstory)\n",
      "                stories.append(newstory)\n",
      "    return stories\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def parse_lines(lines, startidx, name):\n",
      "    thestory = Story()\n",
      "    thestory.kind = name\n",
      "    nextidx = -1\n",
      "    for index,line in enumerate(lines[startidx:]):\n",
      "        if index >= nextidx-startidx:\n",
      "            #print \"%s Line is %s\"%(name, line)\n",
      "            storystart = re.match(\"^\\((\\w+)\",line)\n",
      "            storyend = re.match(\"\\)%s\"%name, line)\n",
      "            if storyend: # we've hit the end of our story; get out and pass it back up\n",
      "                endindex = index\n",
      "                break\n",
      "            elif storystart: # new story; start up a new parse_lines\n",
      "                #print \"in parse_lines, calling parse_lines:\", startidx+index+1, storystart.group(1)\n",
      "                nextidx, newstory = parse_lines(lines, startidx+index + 1, storystart.group(1))\n",
      "                #print \"back\", nextidx, str(newstory)\n",
      "                thestory.story_subobjects.append(newstory)\n",
      "            else:\n",
      "                thestory.process_line(line)\n",
      "    return endindex+startidx+1, thestory\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def extract_particle_dynamics(story):\n",
      "    \"\"\" recursively extract dynamics objects to get masses, positions, and velocities.\n",
      "\n",
      "    Be careful of particles with subparticles.\"\"\"\n",
      "    particles = []\n",
      "    if story.kind == \"Particle\":\n",
      "        if len(story.story_subobjects) > 4:\n",
      "            # get r, v, as center of mass quantities\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Dynamics':\n",
      "                    xcom, ycom, zcom = subobj.story_vals['r'].split(\" \")\n",
      "                    vxcom, vycom, vzcom = subobj.story_vals['v'].split(\" \")\n",
      "            # get relative positions and velocities of sub-particles\n",
      "            subparticles = []\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Particle':\n",
      "                    subparticles.extend(extract_particle_dynamics(subobj))\n",
      "                    \n",
      "            # add COM r, v to sub-particles, and append\n",
      "            for particle in subparticles:\n",
      "                particles.append((particle[0] + float(xcom),\n",
      "                                  particle[1] + float(ycom),\n",
      "                                  particle[2] + float(zcom),\n",
      "                                  particle[3] + float(vxcom),\n",
      "                                  particle[4] + float(vycom),\n",
      "                                  particle[5] + float(vzcom),\n",
      "                                  particle[6]))\n",
      "        else: # only 4 subobjects, so this is an individual star\n",
      "            for subobj in story.story_subobjects:\n",
      "                if subobj.kind == 'Dynamics':\n",
      "                    x,y,z = subobj.story_vals['r'].split(\" \")\n",
      "                    vx,vy,vz = subobj.story_vals['v'].split(\" \")\n",
      "                    m = subobj.story_vals['m']\n",
      "                    particles.append((float(x), float(y), float(z), float(vx), float(vy), float(vz), float(m)) )\n",
      "    return particles\n",
      "    \n",
      "# <codecell>\n",
      "\n",
      "def vis_story_3d(story_list):\n",
      "    \"\"\"visualize a story list. \"\"\"\n",
      "    \n",
      "    xvals = []\n",
      "    yvals = []\n",
      "    zvals = []\n",
      "    vxs = []\n",
      "    vys = []\n",
      "    vzs = []\n",
      "    masses = []\n",
      "    \n",
      "    for story in story_list:\n",
      "        partlist = extract_particle_dynamics(story)\n",
      "        \n",
      "    for particle in partlist:\n",
      "        xvals.append(particle[0])\n",
      "        yvals.append(particle[1])\n",
      "        zvals.append(particle[2])\n",
      "        vxs.append(particle[3])\n",
      "        vys.append(particle[4])\n",
      "        vzs.append(particle[5])\n",
      "        masses.append(particle[6])\n",
      "        \n",
      "    # now do the plot\n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.plot(np.array(xvals), np.array(yvals), np.array(zvals), \".\")\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def premain(startn):\n",
      "    \"\"\"Run a plummer model for 10 dynamical times and return the number of stars remaining.\"\"\"\n",
      "    from subprocess import Popen, PIPE\n",
      "    \n",
      "    print \"running %d particles\" % startn\n",
      "    cmds = []\n",
      "\n",
      "    cmds.append([\"makeplummer\", \"-n\", \"%d\"%startn, \"-i\"])\n",
      "    cmds.append([\"kira\", \"-t\", \"10\", \"-d\", \"1\", \"-D\", \"2\", \"-n\", \"10\", \"-q\", \"0.5\", \"-G\", \"2\"])\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        print index, cmd\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
      "    inp = procs[-1].stdout\n",
      "    \n",
      "    result = procs[-1].communicate()\n",
      "    slist = parse_output(result[0])\n",
      "    return len(extract_particle_dynamics(slist[-1]))\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def grab_energies(slist):\n",
      "    times = []\n",
      "    energies = []\n",
      "    kinetics = []\n",
      "    potentials = []\n",
      "    for story in slist:\n",
      "        times.append(float(slist.story_subobjects[1].story_vals['t']))\n",
      "        energies.append(float(slist.story_subobjects[1].story_vals['total_energy']))\n",
      "        kinetics.append(float(slist.story_subobjects[1].story_vals['kinetic_energy']))\n",
      "        potentials.append(float(slist.story_subobjects[1].story_vals['potential_energy']))\n",
      "    return times, energies, kinetics, potentials\n",
      "# <codecell>\n",
      "\n",
      "def l2norm(E, U, T):\n",
      "    U0 = 2*E[0]\n",
      "    T0 = -E[0]\n",
      "    l2U = sum((np.array(U)-U0)**2)\n",
      "    l2T = sum((np.array(T)-T0)**2)\n",
      "    return l2U, l2T\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def fs_process_commands(cmds):\n",
      "    \"\"\"Process commands, storing the results on the filesystem.\"\"\"\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE))\n",
      "        inp = procs[-1].stdout\n",
      "    result = procs[-1].communicate()\n",
      "\n",
      "    theuuid = uuid.uuid1()\n",
      "    storename = str(theuuid)+\".kiraout\"\n",
      "\n",
      "    #if not os.path.isdir(warehousepath):\n",
      "    #    os.makedirs(warehousepath)\n",
      "\n",
      "    store = open(warehousepath+storename, \"w\")\n",
      "        \n",
      "    store.write(result[0])\n",
      "    store.close()\n",
      "    \n",
      "    return theuuid\n",
      "\n",
      "# <codecell>\n",
      "def fs_panel(storename):\n",
      "    \"\"\"Grab a story list from the filesystem and turn it into a pandas panel.\"\"\"\n",
      "    infile = open(storename, 'rb')\n",
      "    partstart = re.compile(\"^\\(Particle\")\n",
      "    partend = re.compile(\"^\\)Particle\")\n",
      "    dynstart = re.compile(\"^\\(Dynamics\")\n",
      "    dynend = re.compile(\"^\\)Dynamics\")\n",
      "\n",
      "    snap = 0\n",
      "    insnap = False\n",
      "    panbase = pd.Panel()\n",
      "    \n",
      "    for line in infile:\n",
      "        if partstart.match(line):\n",
      "            pass\n",
      "        elif partend.match(line):\n",
      "            pass\n",
      "        elif dynstart.match(line):\n",
      "            pass\n",
      "        elif dynend.match(line):\n",
      "            pass\n",
      "        \n",
      "    return pan\n",
      "\n",
      "\n",
      "# <codecell>\n",
      "def kiraout_to_xml(theuuid):\n",
      "    storebase = str(theuuid)\n",
      "    storename = str(theuuid)+\".kiraout\"\n",
      "    \n",
      "    xmlframes = []\n",
      "\n",
      "    frame = 0\n",
      "    nframes = 0\n",
      "    level = 0\n",
      "    \n",
      "    store = open(warehousepath+storename, \"rb\")\n",
      "\n",
      "    storystart = re.compile(\"^\\((\\w+)\")\n",
      "    storyend = re.compile(\"^\\)(\\w+)\")\n",
      "\n",
      "    for line in store:\n",
      "        if storystart.match(line):\n",
      "            #print \"entering: %s, %d\" % (storystart.match(line).group(1), level)\n",
      "            if level==0:\n",
      "                nframes += 1\n",
      "                xmlname = storebase + \".%d.xml\" % frame\n",
      "                xmlframes.append(xmlname)\n",
      "                xmlfile = open(warehousepath+xmlname, \"wb\")\n",
      "                xmlfile.write('<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>')\n",
      "            level += 1\n",
      "            xmlfile.write(\"<%s>\\n\"%storystart.match(line).group(1))\n",
      "        elif storyend.match(line):\n",
      "            #print \"leaving: %s, %d\" % (storyend.match(line).group(1), level)\n",
      "            level -= 1\n",
      "            xmlfile.write(\"</%s>\\n\"%storyend.match(line).group(1))\n",
      "            if level == 0:\n",
      "                frame += 1\n",
      "                xmlfile.close()\n",
      "        else:\n",
      "            chunks = re.split(\"=\", line)\n",
      "            if len(chunks) == 2:\n",
      "                xmlfile.write(\"<value %s=\\\"%s\\\" />\\n\" %(re.sub(\"\\,* \",\"_\",chunks[0].strip()), chunks[1].strip()))\n",
      "            else:\n",
      "                xmlfile.write(line)\n",
      "\n",
      "    store.close()\n",
      "    return nframes\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "\n",
      "def quantile_radius(pan, quant):\n",
      "    \"\"\"Get the average radius for a given mass quantile.\n",
      "\n",
      "    Compares the average radius for the given mass quantile 0% -> quant\n",
      "    with that of the complement ((1-quant) -> 100%)\n",
      "\n",
      "    Takes inputs:\n",
      "    pan -- pandas panel, where the item index is sorted by mass\n",
      "    quant -- the quantile, in percent, to use.\n",
      "\n",
      "    returns a tuple of time series:\n",
      "    (lightradius, heavyradius, light/heavy) \n",
      "    \"\"\"\n",
      "    indices = sorted(pan.keys(), key=int)\n",
      "    number = int(quant*len(indices))\n",
      "    print \"%d runs in requested quantile\" % number\n",
      "    heavyslice = [pan[index] for index in indices[:number]]\n",
      "    lightslice = [pan[index] for index in indices[-number:]]\n",
      "    \n",
      "    print \"heavy masses:\", [star['m'][0] for star in heavyslice]\n",
      "    print \"light masses:\", [star['m'][0] for star in lightslice]\n",
      "    \n",
      "    heavyr = np.zeros_like(heavyslice[0]['radius'].values)\n",
      "    for star in heavyslice:\n",
      "        heavyr += star['radius'].values\n",
      "    heavyr /= number\n",
      "    \n",
      "    lightr = np.zeros_like(lightslice[0]['radius'].values)\n",
      "    for star in lightslice:\n",
      "        lightr += star['radius'].values\n",
      "    lightr /= number\n",
      "    \n",
      "    ratio = lightr/heavyr\n",
      "    return lightr, heavyr, ratio\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "from matplotlib import animation\n",
      "def animate_panel_old(pan, prng=10.0, filebase='basic_animation'):\n",
      "    \"\"\"Turn a panel of star cluster evolution snapshots into a 3d animation.\n",
      "\n",
      "    Arguments are:\n",
      "    pan: the panel\n",
      "    prng: plot range for all three axes.\n",
      "    filebase: the base name of the file for the animation.\n",
      "\n",
      "    returns:\n",
      "    Nothing.\"\"\"\n",
      "    \n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.set_autoscale_on(False)\n",
      "    \n",
      "    nframes = pan.shape[1]\n",
      "    starfield, = ax.plot([], [], [],'bo', ms=7)\n",
      "    ax.set_xlim3d(-prng, prng)\n",
      "    ax.set_ylim3d(-prng, prng)\n",
      "    ax.set_zlim3d(-prng, prng)\n",
      "\n",
      "    def init():\n",
      "        \"\"\"initialize animation\"\"\"\n",
      "        starfield.set_data([], [])\n",
      "        starfield.set_3d_properties(zs=[])\n",
      "        return starfield\n",
      "    \n",
      "    def doframe(n):\n",
      "        xvals = []\n",
      "        yvals = []\n",
      "        zvals = []\n",
      "        masses = []\n",
      "        \n",
      "        for starid in pan.keys():\n",
      "            xvals.append(pan[starid]['r'][n][0])\n",
      "            yvals.append(pan[starid]['r'][n][1])\n",
      "            zvals.append(pan[starid]['r'][n][2])\n",
      "            masses.append(pan[starid]['m'][n])\n",
      "    # not super happy with the colors yet.\n",
      "        starfield.set_data(np.array(xvals), np.array(yvals))\n",
      "        starfield.set_3d_properties(zs=np.array(zvals))\n",
      "        return starfield\n",
      "\n",
      "    anim = animation.FuncAnimation(fig, doframe,\n",
      "                               frames=nframes, interval=20, blit=True)\n",
      "    anim.save(\"%s.mp4\"%filebase, fps=30)\n",
      "    #ax.plot(np.array(xvals), np.array(yvals), np.array(zvals), \".\")\n",
      "\n",
      "\n",
      "def animate_from_fs(filebase, nframes, prng=10.0, use_warehouse=True):\n",
      "    import pylab as plt\n",
      "    from mpl_toolkits.mplot3d import axes3d\n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.set_autoscale_on(False)\n",
      "\n",
      "    mcomfield, = ax.plot([], [], [],'go', ms=7)\n",
      "    ax.set_xlim3d(-prng, prng)\n",
      "    ax.set_ylim3d(-prng, prng)\n",
      "    ax.set_zlim3d(-prng, prng)\n",
      "\n",
      "    def init():\n",
      "        \"\"\"initialize animation\"\"\"\n",
      "        mcomfield.set_data([], [])\n",
      "        mcomfield.set_3d_properties(zs=[])\n",
      "        return (mcomfield)\n",
      "    \n",
      "    def doframe(n):\n",
      "        xvals = []\n",
      "        yvals = []\n",
      "        zvals = []\n",
      "        masses = []\n",
      "        \n",
      "        if use_warehouse:\n",
      "            xmlname = warehousepath + filebase + \".%d.xml\"% n\n",
      "        else:\n",
      "            xmlname = filebase + \".%d.xml\"% n\n",
      "            \n",
      "        dataframe, time, nparticles = process_frame(xmlname)\n",
      "        \n",
      "        xvals = dataframe.xs('x').values\n",
      "        yvals = dataframe.xs('y').values\n",
      "        zvals = dataframe.xs('z').values\n",
      "        \n",
      "        mcomfield.set_data(dataframe.xs('x_mcom').values, dataframe.xs('y_mcom').values)\n",
      "        mcomfield.set_3d_properties(zs=np.array(dataframe.xs('z_mcom').values))\n",
      "        return (mcomfield)\n",
      "\n",
      "    anim = animation.FuncAnimation(fig, doframe,\n",
      "                               frames=nframes, interval=20, blit=True)\n",
      "    moviename = \"%s.mp4\"%filebase\n",
      "    anim.save(moviename, fps=30, bitrate=4000)\n",
      "    return moviename\n",
      "\n",
      "def str_to_vect(vectstr):\n",
      "    return np.array(vectstr.split(\" \"), float)\n",
      "\n",
      "def process_frame(xmlname):\n",
      "    frame = etree.parse(xmlname)\n",
      "    nparticles = int(frame.xpath('/Particle/value[@ N]/@ N')[0])\n",
      "    time = float(frame.xpath('/Particle/Dynamics/value[@ t]/@ t')[0])\n",
      "    \n",
      "    center_r = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ r]/@ r')[0])\n",
      "    com_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ com_pos]/@ com_pos')[0])\n",
      "    mcom_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ mcom_pos]/@ mcom_pos')[0])\n",
      "    mass_scale = float(frame.xpath('/Particle/Star/value[@ mass_scale]/@ mass_scale')[0])\n",
      "    time_scale = float(frame.xpath('/Particle/Star/value[@ time_scale]/@ time_scale')[0])\n",
      "    size_scale = float(frame.xpath('/Particle/Star/value[@ size_scale]/@ size_scale')[0])\n",
      "\n",
      "    particledict = {}\n",
      "    for part in frame.xpath('/Particle/Particle'):\n",
      "        subpartdict = flatten_particle(part)\n",
      "        particledict.update(subpartdict)\n",
      "    for key in particledict.keys():\n",
      "        particledict[key]['x_mcom'] = particledict[key]['x'] - mcom_pos[0] + center_r[0]\n",
      "        particledict[key]['y_mcom'] = particledict[key]['y'] - mcom_pos[1] + center_r[1]\n",
      "        particledict[key]['z_mcom'] = particledict[key]['z'] - mcom_pos[2] + center_r[2]\n",
      "        particledict[key]['x_com'] = particledict[key]['x'] - com_pos[0] + center_r[0]\n",
      "        particledict[key]['y_com'] = particledict[key]['y'] - com_pos[1] + center_r[1]\n",
      "        particledict[key]['z_com'] = particledict[key]['z'] - com_pos[2] + center_r[2]\n",
      "    framedataframe = pd.DataFrame(particledict)\n",
      "    \n",
      "    return framedataframe, time, nparticles\n",
      "\n",
      "def xml_to_panel(basename, nframes):\n",
      "    paneldict = {}\n",
      "    for frame in xrange(nframes):\n",
      "        xmlname = basename + \".%d.xml\"%frame\n",
      "        df, time, nparticles = process_frame(xmlname)\n",
      "        paneldict[time] = df\n",
      "    thepanel = pd.Panel(paneldict)\n",
      "    return thepanel.transpose(items='minor', major='items', minor='major')\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def process_commands(cmds):\n",
      "    procs = []\n",
      "    for index, cmd in enumerate(cmds):\n",
      "        if index > 0:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
      "        else:\n",
      "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
      "        inp = procs[-1].stdout\n",
      "    \n",
      "    result = procs[-1].communicate()\n",
      "    return result\n",
      "\n",
      "def story_list_to_panel(slist):\n",
      "    nsnaps = len(slist)\n",
      "    nstars = slist[0].story_vals['N']\n",
      "    dict_for_panel = {}\n",
      "    \n",
      "    for snapnum, snapstory in enumerate(slist):\n",
      "        partlist = flatten_parts(snapstory.story_subobjects[4:], snapstory.story_subobjects[1])\n",
      "        for part in partlist:\n",
      "            # make the star dict if necessary\n",
      "            starlabel = part[\"i\"]\n",
      "            pos = part['r']\n",
      "            radius = np.sqrt(pos.dot(pos))\n",
      "            if dict_for_panel.get(starlabel,None) == None:\n",
      "                dict_for_panel[starlabel] = {}\n",
      "                for key in part.keys():\n",
      "                    dict_for_panel[starlabel][key] = [ part[key] ]\n",
      "                dict_for_panel[starlabel]['radius'] = [ radius ]\n",
      "            else:\n",
      "                for key in part.keys():\n",
      "                    try:\n",
      "                        dict_for_panel[starlabel][key].append(part[key])\n",
      "                    except KeyError:\n",
      "                        dict_for_panel[starlabel][key] = [ None ] * snapnum\n",
      "                        dict_for_panel[starlabel][key].append(part[key])\n",
      "                dict_for_panel[starlabel]['radius'].append(radius)\n",
      "            # check to see if anything is missing...\n",
      "            reflength = len(dict_for_panel[starlabel]['radius'])\n",
      "            for key in dict_for_panel[starlabel].keys():\n",
      "                if len(dict_for_panel[starlabel][key]) < reflength:\n",
      "                       #print \"Whoa. problem. i=%s, t=%s, key=%s\" % (starlabel, snapnum, key)\n",
      "                       dict_for_panel[starlabel][key].append(None)\n",
      "\n",
      "#    print \"number of stars: \",len(dict_for_panel.keys())\n",
      "#    for key in dict_for_panel.keys():\n",
      "#        lengthlist = [len(dict_for_panel[key][subkey]) for subkey in dict_for_panel[key].keys()]\n",
      "#        print key, lengthlist\n",
      "#        print dict_for_panel[key].keys()\n",
      "#        print \"-------------------------\\n\\n\"\n",
      "        \n",
      "    thepanel = pd.Panel(dict_for_panel)\n",
      "    return thepanel\n",
      "\n",
      "def flatten_parts(partlist, parentinfo):\n",
      "    flattened = []\n",
      "    for partnum, part in enumerate(partlist):\n",
      "        if len(part.story_subobjects) > 4:\n",
      "            flattened.extend(flatten_parts(part.story_subobjects[4:], part.story_subobjects[1]))\n",
      "        else:\n",
      "            partdict = dict(part.story_vals, **part.story_subobjects[1].story_vals)\n",
      "            flattened.append(partdict)\n",
      "    # deal with positions\n",
      "    pos = np.array(parentinfo.story_vals['r'].split(\" \"), float)\n",
      "    for part in flattened:\n",
      "        try:\n",
      "            part['r'] = part['r'] + pos\n",
      "        except TypeError:\n",
      "            part['r'] = np.array(part['r'].split(\" \"), float) + pos\n",
      "    return flattened\n",
      "\n",
      "\n",
      "def single_run(therun):\n",
      "    \"\"\"Perform a single run from a Run object.\"\"\"\n",
      "    cmds = []\n",
      "\n",
      "    if therun.kingmodel:\n",
      "        cmds.append([\"makeking\",\n",
      "                      \"-n\", \"%d\"%therun.nstars,\n",
      "                      \"-w\", \"%3.1f\"%therun.w0,\n",
      "                      \"-i\"])\n",
      "    else:\n",
      "        cmds.append([\"makeplummer\",\n",
      "                      \"-n\", \"%d\"%therun.nstars,\n",
      "                      \"-i\"])\n",
      "\n",
      "    cmds.append([\"makemass\",\n",
      "                  \"-f\", \"%d\"%therun.masstype,\n",
      "                  \"-l\", \"%f\"%therun.lowerlimit,\n",
      "                  \"-u\", \"%f\"%therun.upperlimit,\n",
      "                  \"-i\"])\n",
      "\n",
      "    cmds.append([\"scale\",\n",
      "                  \"-m\", \"1\",\n",
      "                  \"-e\", \"-0.25\",\n",
      "                  \"-q\", \"0.5\"])\n",
      "\n",
      "    cmds.append([\"kira\", \"-t\", \"%d\"%therun.runlength,\n",
      "                  \"-d\", \"%f\"%therun.diagout,\n",
      "                  \"-D\", \"%f\"%therun.dumpout,\n",
      "                  \"-n\", \"10\",\n",
      "                  \"-q\", \"0.5\"])\n",
      "\n",
      "    therun.uuid = fs_process_commands(cmds)\n",
      "    therun.nframes = kiraout_to_xml(therun.uuid)\n",
      "    return therun\n",
      "\n",
      "def animate_run(therun):\n",
      "    theuuid = therun.uuid\n",
      "    moviename = animate_from_fs(str(theuuid), therun.nframes, use_warehouse=True)\n",
      "    return moviename\n",
      "\n",
      "def flatten_particle(part):\n",
      "    \"\"\"Turn a prarticle into a dictionary with the appropriate values, recursing if necessary.\"\"\"\n",
      "    nparticles = int(part.xpath('./value[@ N]/@ N')[0])\n",
      "    #print nparticles\n",
      "    r = str_to_vect(part.xpath('./Dynamics/value[@ r]/@ r')[0])\n",
      "    v = str_to_vect(part.xpath('./Dynamics/value[@ v]/@ v')[0])\n",
      "    \n",
      "    if nparticles == 1:\n",
      "        parti = int(part.xpath('./value[@ i]/@ i')[0])\n",
      "        m = float(part.xpath('./Dynamics/value[@ m]/@ m')[0])\n",
      "        radius = np.sqrt(r.dot(r))\n",
      "        pot = float(part.xpath('./Dynamics/value[@ pot]/@ pot')[0])\n",
      "        partdict = {parti: {'x':r[0], 'y':r[1], 'z':r[2], 'm':m, 'radius':radius} }\n",
      "        partdict[parti].update({'vx':v[0], 'vy':v[1], 'vz':v[2], 'pot':pot})\n",
      "    else:\n",
      "        # this node is not a leaf; we have to do the subtree\n",
      "        partdict = {}\n",
      "        for subpart in part.xpath('./Particle'):\n",
      "            tpd = flatten_particle(subpart)\n",
      "            #print tpd\n",
      "            partdict.update(tpd)\n",
      "        for key in partdict.keys():\n",
      "            partdict[key]['x'] += r[0]\n",
      "            partdict[key]['y'] += r[1]\n",
      "            partdict[key]['z'] += r[2]\n",
      "            partdict[key]['vx'] += v[0]\n",
      "            partdict[key]['vy'] += v[1]\n",
      "            partdict[key]['vz'] += v[2]\n",
      "            partdict[key]['radius'] = np.sqrt(partdict[key]['x']**2+partdict[key]['y']**2+partdict[key]['z']**2)\n",
      "            partdict[key]['kinetic'] = (partdict[key]['vx']**2+partdict[key]['vy']**2+partdict[key]['vz']**2)*partdict[key]['m']/2.0\n",
      "    return partdict\n",
      "\n",
      "def extract_from_frame(therun, framenum):\n",
      "    filebase = str(therun.uuid)\n",
      "    xmlname = '.warehouse/' + filebase + \".%d.xml\" % framenum\n",
      "    frame = etree.parse(xmlname)\n",
      "\n",
      "    extracted = {}\n",
      "    \n",
      "    nparticles = int(frame.xpath('/Particle/value[@ N]/@ N')[0])\n",
      "    time = float(frame.xpath('/Particle/Dynamics/value[@ t]/@ t')[0])\n",
      "\n",
      "    center_r = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ r]/@ r')[0])\n",
      "    com_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ com_pos]/@ com_pos')[0])\n",
      "    mcom_pos = str_to_vect(frame.xpath('/Particle/Dynamics/value[@ mcom_pos]/@ mcom_pos')[0])\n",
      "    mass_scale = float(frame.xpath('/Particle/Star/value[@ mass_scale]/@ mass_scale')[0])\n",
      "    time_scale = float(frame.xpath('/Particle/Star/value[@ time_scale]/@ time_scale')[0])\n",
      "    size_scale = float(frame.xpath('/Particle/Star/value[@ size_scale]/@ size_scale')[0])\n",
      "\n",
      "    particledict = {}\n",
      "    for part in frame.xpath('/Particle/Particle'):\n",
      "        subpartdict = flatten_particle(part)\n",
      "        particledict.update(subpartdict)\n",
      "    for key in particledict.keys():\n",
      "        particledict[key]['x_mcom'] = particledict[key]['x'] - mcom_pos[0] + center_r[0]\n",
      "        particledict[key]['y_mcom'] = particledict[key]['y'] - mcom_pos[1] + center_r[1]\n",
      "        particledict[key]['z_mcom'] = particledict[key]['z'] - mcom_pos[2] + center_r[2]\n",
      "        particledict[key]['x_com'] = particledict[key]['x'] - com_pos[0] + center_r[0]\n",
      "        particledict[key]['y_com'] = particledict[key]['y'] - com_pos[1] + center_r[1]\n",
      "        particledict[key]['z_com'] = particledict[key]['z'] - com_pos[2] + center_r[2]\n",
      "        particledict[key]['radius'] = np.sqrt(particledict[key]['x_mcom']**2 +\n",
      "                                              particledict[key]['y_mcom']**2 +\n",
      "                                              particledict[key]['z_mcom']**2)\n",
      "    framedataframe = pd.DataFrame(particledict)\n",
      "\n",
      "    return framedataframe, time, nparticles\n",
      "\n",
      "def run_to_panel(therun):\n",
      "    nframes = int(therun.runlength/therun.dumpout)\n",
      "    paneldict={}\n",
      "    for frame in xrange(nframes):\n",
      "        df, time, nparticles = extract_from_frame(therun, frame)\n",
      "        paneldict[time] = df\n",
      "    thepanel = pd.Panel(paneldict)\n",
      "    return thepanel.transpose(items='major', major='minor', minor='items')\n",
      "\n",
      "def massradius(pan, quantity='radius', fraction=0.1):\n",
      "    times = pan[quantity].keys()\n",
      "    high_mass_radius_list = []\n",
      "    low_mass_radius_list = []\n",
      "    nstars = pan[quantity][times[0]].count()\n",
      "    nfrac = int(nstars * fraction)\n",
      "    \n",
      "    hmseries = pan[quantity][0:nfrac].median()\n",
      "    lmseries = pan[quantity][-nfrac:-1].median()\n",
      "    ratioseries = lmseries/hmseries\n",
      "        #print time, hmr, lmr\n",
      "        \n",
      "#    lmseries = pd.Series(data=low_mass_radius_list, index=times)\n",
      "#    hmseries = pd.Series(data=high_mass_radius_list, index=times)\n",
      "#    ratioseries = pd.Series(data=ratios, index=times)\n",
      "    return(ratioseries, lmseries, hmseries)\n",
      "\n",
      "def list_ensembles():\n",
      "    ensfiles= glob.glob('./*.ensemble')\n",
      "    print \"%d ensembles:\\n\" % len(ensfiles)\n",
      "    for ensf in ensfiles:\n",
      "        ensfile = open(ensf, 'rb')\n",
      "        try:\n",
      "            runslist = pickle.load(ensfile)\n",
      "            nruns = len(runslist)\n",
      "            nstars = runslist[0].nstars\n",
      "            if runslist[0].kingmodel:\n",
      "                model = \"King\"\n",
      "            else:\n",
      "                model = \"Plummer\"\n",
      "            print \"%s -- %s model; %d runs %d stars \" %(ensf, model, nruns, nstars)\n",
      "        except EOFError:\n",
      "            print \"%s -- No data\" %ensf\n",
      "        ensfile.close()\n",
      "\n",
      "\n",
      "def avg_series(ensname, output=False):\n",
      "    storename = \"%s-avg.h5\"%ensname\n",
      "    store = pd.HDFStore(\"%s-avg.h5\"%ensname)\n",
      "    try:\n",
      "        ratiodf = store['ratiodf']\n",
      "        lowdf = store['lowdf']\n",
      "        highdf = store['highdf']\n",
      "    except KeyError:\n",
      "        ensfile = open(ensname, 'rb')\n",
      "        runlist = pickle.load(ensfile)\n",
      "\n",
      "        rsdict = {}\n",
      "        lsdict = {}\n",
      "        hsdict = {}\n",
      "        i = 0\n",
      "        for run in runlist:\n",
      "            key = \"%d\"%i\n",
      "            if output:\n",
      "                print key\n",
      "            try:\n",
      "                thepan = run_to_panel(run)\n",
      "                rseries, lmseries, hmseries = massradius(thepan)\n",
      "                rsdict[key] = rseries\n",
      "                lsdict[key] = lmseries\n",
      "                hsdict[key] = hmseries\n",
      "            except IOError:\n",
      "                pass\n",
      "            i+=1\n",
      "        highdf = pd.DataFrame(hsdict)\n",
      "        lowdf = pd.DataFrame(lsdict)\n",
      "        ratiodf = pd.DataFrame(rsdict)\n",
      "    \n",
      "        # compute averages\n",
      "        highdf['avg'] = highdf.mean(axis=1)\n",
      "        lowdf['avg'] = lowdf.mean(axis=1)\n",
      "        ratiodf['avg'] = ratiodf.mean(axis=1)\n",
      "    \n",
      "        # compute stddev\n",
      "        highdf['stddev'] = highdf.std(axis=1)\n",
      "        lowdf['stddev'] = lowdf.std(axis=1)\n",
      "        ratiodf['stddev'] = ratiodf.std(axis=1)\n",
      " \n",
      "        store['highdf'] = highdf\n",
      "        store['lowdf'] = lowdf\n",
      "        store['ratiodf'] = ratiodf\n",
      "        \n",
      "    return ratiodf, lowdf, highdf\n",
      "\n",
      "def r_and_m(clusterstep):\n",
      "    rvals = []\n",
      "    masses = []\n",
      "    \n",
      "# determine the radii and masses of stars for a timestep in kira output\n",
      "# uses extract_particle_dynamics to open story and create lists of stars\n",
      "    \n",
      "    partlist = extract_particle_dynamics(clusterstep)\n",
      "    \n",
      "    for particle in partlist:\n",
      "        masses.append(particle[6])\n",
      "        x = particle[0]\n",
      "        y = particle[1]\n",
      "        z = particle[2]\n",
      "        r = np.sqrt(x*x + y*y + z*z)\n",
      "        rvals.append(r)\n",
      "#        print r, particle[6]\n",
      "        \n",
      "    return rvals, masses\n",
      "\n",
      "def medianpos(mlow, mhigh, rad, masses):\n",
      "    index = 0\n",
      "    r_lowmass = []\n",
      "    r_highmass = []\n",
      "    \n",
      "# find median radius for stars below a low mass cut-off and above\n",
      "# a high-mass cut-off given the desired cut-offs as well as lists of\n",
      "# radii and masses (ordered the same)\n",
      "    \n",
      "    for mass in masses:\n",
      "        if mass <= mlow:\n",
      "            r_lowmass.append(rad[index])\n",
      "        if mass >= mhigh:\n",
      "            r_highmass.append(rad[index])\n",
      "        index = index + 1\n",
      "        \n",
      "    medlow = np.median(r_lowmass)\n",
      "    medhigh = np.median(r_highmass)\n",
      "    \n",
      "    return medlow, medhigh\n",
      "\n",
      "def medianpos_percentile(storylist):\n",
      "    masscut = 0.1\n",
      "    first = 1\n",
      "    median_low = []\n",
      "    median_high = []\n",
      "    \n",
      "# takes a storylist generated from kira output and produces a list of\n",
      "# median star positions for stars in the upper & lower percentile as\n",
      "# set in the parameter \"masscut\", above\n",
      "\n",
      "# when looking at the initial timestep, it uses the percentile to figure\n",
      "# out actual cut-offs in mass.  This way, we do not have to worry about \n",
      "# evaporation changing which stars fall in our observed bins.  \n",
      "    \n",
      "    for story in storylist:\n",
      "        (radii, masses) = r_and_m(story)\n",
      "        if first == 1:\n",
      "            masssort = np.sort(masses)\n",
      "            nummass = len(masses)\n",
      "            indexlo = int(np.floor(masscut * nummass))\n",
      "            indexhi = int(np.floor(nummass - indexlo))\n",
      "            masslow = masssort[indexlo]\n",
      "            masshigh = masssort[indexhi]\n",
      "            print masslow, masshigh\n",
      "            first = 0\n",
      "        (medlow, medhigh) = medianpos(masslow, masshigh, radii, masses)\n",
      "        median_low.append(medlow)\n",
      "        median_high.append(medhigh)\n",
      "    return median_low, median_high\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%save starlibrary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File `starlibrary.py` exists. Overwrite (y/[N])?  y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'' was not found in history, as a file, url, nor in the user namespace.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}